{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"filtered-links_1.txt\", \"r\")\n",
    "hrefs = []\n",
    "while True:\n",
    "    content = file.readline()\n",
    "    if content:\n",
    "        hrefs.append(content.strip())  # Using strip() to remove the newline character\n",
    "    else:\n",
    "        break\n",
    "\n",
    "file.close()\n",
    "\n",
    "file = open(\"filtered-links_2.txt\", \"r\")\n",
    "while True:\n",
    "    content = file.readline()\n",
    "    if content:\n",
    "        hrefs.append(content.strip())  # Using strip() again here\n",
    "    else:\n",
    "        break\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://jlptsensei.com/learn-japanese-vocabulary/%e6%b5%b4%e3%81%b3%e3%82%8b-%e3%81%82%e3%81%b3%e3%82%8b-abiru-meaning/']\n"
     ]
    }
   ],
   "source": [
    "print(hrefs[:1]) #there should be 120 links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from tqdm import tqdm\n",
    "\n",
    "service = webdriver.ChromeService()\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "data_array = []\n",
    "\n",
    "for link in tqdm(hrefs[116:]):\n",
    "    # print(\"getting link\")\n",
    "    # t = time.time()\n",
    "    driver.set_page_load_timeout(8)\n",
    "    try:\n",
    "        driver.get(link)\n",
    "    except TimeoutException:\n",
    "        driver.execute_script(\"window.stop();\")\n",
    "    # print('Time consuming:', time.time() - t)\n",
    "    \n",
    "    # print(\"extract info\")\n",
    "    # 60% work tbh..need to figure out loading and bot detection but easier to hardcode\n",
    "        \n",
    "    vocab_title =   driver.find_element(By.CLASS_NAME, 'd-block.p-3.vocab-title-2.jp').text\n",
    "    eng_definition =  driver.find_element(By.CLASS_NAME, 'eng-definition.p-lg.mb-lg-5').text\n",
    "    # Locate the <div> tag by its class name\n",
    "    \n",
    "    try:\n",
    "        div_element = driver.find_element(By.CSS_SELECTOR, \"div.goi-notes.p-3.pb-0.bg-light-grey.mb-3.clearfix\")\n",
    "        verb_type = \"error\"\n",
    "        # print(div_element.get_attribute('outerHTML'))\n",
    "        # Now, find all <p> tags within this <div>\n",
    "        p_tags = div_element.find_elements(By.TAG_NAME, \"p\")\n",
    "        # Ensure there are at least three <p> tags\n",
    "        # print(p_tags)\n",
    "        # Select the third <p> tag (index 2 since it's 0-based)\n",
    "        third_p_tag = p_tags[-2]\n",
    "        \n",
    "        full_html = third_p_tag.get_attribute('outerHTML')\n",
    "        # print(full_html)\n",
    "        # This is a workaround to get the text immediately after the <strong> tag.\n",
    "        parts = full_html.split('</strong>')\n",
    "        # print(parts)\n",
    "        text_after_strong = parts[1]\n",
    "\n",
    "        parts = text_after_strong.split(', ')\n",
    "\n",
    "        desired_parts = parts[1:]  # This will give you [\"string2\", \"string3</p>\"]\n",
    "        joined_string = ', '.join(desired_parts)\n",
    "        verb_type = joined_string\n",
    "        cleaned_string = joined_string.replace('</p>', '')\n",
    "        verb_type = cleaned_string\n",
    "    \n",
    "        data_array.append((vocab_title, eng_definition, verb_type))\n",
    "    except:\n",
    "        data_array.append((vocab_title, eng_definition, \"UNKNOWN\"))\n",
    "\n",
    "\n",
    "# Don't forget to close the browser\n",
    "driver.quit()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
